import logging
import numpy as np
from typing import List
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# models.pyì—ì„œ ì •ì˜í•œ í´ë˜ìŠ¤ë“¤ ì„í¬íŠ¸
from models import ResumeAnalysis, JobPostingResult, JobMatchResult

logger = logging.getLogger("uvicorn")

class JobMatcher:
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(JobMatcher, cls).__new__(cls)
        return cls._instance

    def load_model(self):
        if self._model is None:
            print("\nâš™ï¸ [System] AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            self._model = SentenceTransformer('all-MiniLM-L6-v2')
            print("âœ… [System] ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n")

    def _create_user_text(self, user: ResumeAnalysis) -> str:
        text = f"í¬ë§ ì§ë¬´: {user.desired_job}. "
        text += f"ë³´ìœ  ê¸°ìˆ : {', '.join(user.skills)}. "
        for proj in user.projects:
            techs = ", ".join(proj.tech_stack)
            text += f"í”„ë¡œì íŠ¸ {proj.name}: {techs} í™œìš©, {proj.description}. "
        for exp in user.experiences:
            text += f"{exp} "
        return text

    def _create_job_text(self, job: JobPostingResult) -> str:
        text = f"{job.title}. "
        res = job.responsibilities if job.responsibilities else []
        qual = job.qualifications if job.qualifications else []
        text += f"ë‹´ë‹¹ ì—…ë¬´: {' '.join(res)}. "
        text += f"ìê²© ìš”ê±´: {' '.join(qual)}. "
        return text

    def calculate_scores(self, user: ResumeAnalysis, jobs: List[JobPostingResult]) -> List[JobMatchResult]:
        self.load_model()
        
        if not jobs:
            return []

        # [ë””ë²„ê¹…] ì‚¬ìš©ì í…ìŠ¤íŠ¸ í™•ì¸
        user_text = self._create_user_text(user)
        print(f"\nğŸ‘¤ [User Text]: {user_text[:100]}...") # ì• 100ìë§Œ ì¶œë ¥

        job_texts = []
        for job in jobs:
            j_text = self._create_job_text(job)
            job_texts.append(j_text)
            # [ë””ë²„ê¹…] ê³µê³  í…ìŠ¤íŠ¸ í™•ì¸
            # print(f"   ğŸ¢ [Job Text]: {j_text[:50]}...") 

        # ì„ë² ë”© ë° ì ìˆ˜ ê³„ì‚°
        user_vector = self._model.encode([user_text])
        job_vectors = self._model.encode(job_texts)
        similarities = cosine_similarity(user_vector, job_vectors)[0]

        results = []
        print("\nğŸ“Š [ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ê²°ê³¼]")
        print("-" * 50)
        
        for i, score in enumerate(similarities):
            match_score = round(float(score) * 100, 1)
            job_title = jobs[i].title
            
            # [ë””ë²„ê¹…] ì ìˆ˜ ë¡œê·¸ ì¶œë ¥
            print(f"   ğŸ”¹ {job_title[:20]}... : {match_score}ì ")

            if match_score >= 70:
                analysis = "ğŸŒŸ AI ê°•ë ¥ ì¶”ì²œ (ì§ë¬´/ìŠ¤íƒ ì¼ì¹˜ë„ ë§¤ìš° ë†’ìŒ)"
            elif match_score >= 50:
                analysis = "âœ… ì í•© (í•µì‹¬ ì—­ëŸ‰ ë¶€í•©)"
            elif match_score >= 30:
                analysis = "ğŸ¤” ê²€í†  í•„ìš” (ì¼ë¶€ ì—°ê´€ì„± ìˆìŒ)"
            else:
                analysis = "âš ï¸ ê´€ë ¨ì„± ë‚®ìŒ"

            job_data = jobs[i].model_dump()
            results.append(JobMatchResult(
                **job_data,
                match_score=match_score,
                ai_analysis=analysis
            ))

        print("-" * 50 + "\n")

        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x.match_score, reverse=True)
        return results

def get_matcher():
    return JobMatcher()