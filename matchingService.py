import logging
import numpy as np
from typing import List
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# models.pyì—ì„œ ì •ì˜í•œ í´ë˜ìŠ¤ë“¤ ì„í¬íŠ¸
from models import ResumeAnalysis, JobPostingResult, JobMatchResult

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("uvicorn")

class JobMatcher:
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(JobMatcher, cls).__new__(cls)
        return cls._instance

    def load_model(self):
        """ëª¨ë¸ì´ ì—†ì„ ë•Œë§Œ ë¡œë”© (Lazy Loading)"""
        if self._model is None:
            logger.info("âš™ï¸ [Cold Start] ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ëŠ” ì¤‘... (ì•½ 3~5ì´ˆ ì†Œìš”)")
            self._model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    # â–¼ [ë³µêµ¬ë¨] ì´ í•¨ìˆ˜ë“¤ì´ ê¼­ ìˆì–´ì•¼ í•©ë‹ˆë‹¤!
    def _create_user_text(self, user: ResumeAnalysis) -> str:
        """ì´ë ¥ì„œ ê°ì²´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text = f"í¬ë§ ì§ë¬´: {user.desired_job}. "
        text += f"ë³´ìœ  ê¸°ìˆ : {', '.join(user.skills)}. "
        
        for proj in user.projects:
            techs = ", ".join(proj.tech_stack)
            text += f"í”„ë¡œì íŠ¸ {proj.name}: {techs} í™œìš©, {proj.description}. "
            
        for exp in user.experiences:
            text += f"{exp} "
            
        return text

    def _create_job_text(self, job: JobPostingResult) -> str:
        """ì±„ìš©ê³µê³  ê°ì²´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text = f"{job.title}. "
        # ë¦¬ìŠ¤íŠ¸ê°€ Noneì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        res = job.responsibilities if job.responsibilities else []
        qual = job.qualifications if job.qualifications else []
        
        text += f"ë‹´ë‹¹ ì—…ë¬´: {' '.join(res)}. "
        text += f"ìê²© ìš”ê±´: {' '.join(qual)}. "
        return text
    # â–² ì—¬ê¸°ê¹Œì§€

    def calculate_scores(self, user: ResumeAnalysis, jobs: List[JobPostingResult]) -> List[JobMatchResult]:
        # ê³„ì‚° ì§ì „ì— ëª¨ë¸ ë¡œë”© í™•ì¸ (Lazy Loading)
        self.load_model()
        
        if not jobs:
            return []

        # 1. í…ìŠ¤íŠ¸ ë³€í™˜ (ì´ì œ ì—ëŸ¬ ì•ˆ ë‚¨)
        user_text = self._create_user_text(user)
        job_texts = [self._create_job_text(job) for job in jobs]

        # 2. ì„ë² ë”© (Vectorization)
        user_vector = self._model.encode([user_text])
        job_vectors = self._model.encode(job_texts)

        # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(user_vector, job_vectors)[0]

        # 4. ê²°ê³¼ ë§¤í•‘
        results = []
        for i, score in enumerate(similarities):
            match_score = round(float(score) * 100, 1)
            
            # AI ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„±
            if match_score >= 70:
                analysis = "ğŸŒŸ AI ê°•ë ¥ ì¶”ì²œ (ì§ë¬´/ìŠ¤íƒ ì¼ì¹˜ë„ ë§¤ìš° ë†’ìŒ)"
            elif match_score >= 50:
                analysis = "âœ… ì í•© (í•µì‹¬ ì—­ëŸ‰ ë¶€í•©)"
            elif match_score >= 30:
                analysis = "ğŸ¤” ê²€í†  í•„ìš” (ì¼ë¶€ ì—°ê´€ì„± ìˆìŒ)"
            else:
                analysis = "âš ï¸ ê´€ë ¨ì„± ë‚®ìŒ"

            # ì›ë³¸ ë°ì´í„°ì— ì ìˆ˜ì™€ ë¶„ì„ ì¶”ê°€
            job_data = jobs[i].model_dump()
            results.append(JobMatchResult(
                **job_data,
                match_score=match_score,
                ai_analysis=analysis
            ))

        # 5. ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x.match_score, reverse=True)
        return results

# ì™¸ë¶€ì—ì„œ ì‰½ê²Œ ì“°ë„ë¡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜ ì œê³µ
def get_matcher():
    return JobMatcher()